{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5df283d-2b84-4993-bc57-c76990b5339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Tokenization', 'is', 'an', 'important', 'NLP', 'technique', '.', 'It', 'involves', 'breaking', 'down', 'text', 'into', 'smaller', 'units', ',', 'such', 'as', 'words', 'or', 'subwords', '.']\n",
      "\n",
      "Stemmed words: ['token', 'is', 'an', 'import', 'nlp', 'techniqu', '.', 'it', 'involv', 'break', 'down', 'text', 'into', 'smaller', 'unit', ',', 'such', 'as', 'word', 'or', 'subword', '.']\n",
      "\n",
      "Lemmatized words: ['Tokenization', 'be', 'an', 'important', 'NLP', 'technique', '.', 'It', 'involve', 'break', 'down', 'text', 'into', 'smaller', 'units', ',', 'such', 'as', 'word', 'or', 'subwords', '.']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Deepak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Deepak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "\n",
    "# Download necessary NLTK resources (only required once)\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Sample text\n",
    "text = \"Tokenization is an important NLP technique. It involves breaking down text into smaller units, such as words or subwords.\"\n",
    "\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "print()\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(token) for token in tokens]\n",
    "print(\"Stemmed words:\", stemmed_words)\n",
    "print()\n",
    "\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(token, wordnet.VERB) for token in tokens]\n",
    "print(\"Lemmatized words:\", lemmatized_words)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a018fc-9fbc-4c96-a802-b5d3c8213018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\deepak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.4.16-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 20.5/42.0 kB 640.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 42.0/42.0 kB 406.8 kB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\deepak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.5 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.8/1.5 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.2/1.5 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 5.6 MB/s eta 0:00:00\n",
      "Downloading regex-2024.4.16-cp311-cp311-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 268.9/268.9 kB 5.6 MB/s eta 0:00:00\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.7 nltk-3.8.1 regex-2024.4.16 tqdm-4.66.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980a01ff-cb16-4a7d-a38d-e157f1121e15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
